{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "loaded\n",
      "0 0\n",
      "1 6\n",
      "2 12\n",
      "3 636\n",
      "4 11208\n",
      "5 263880\n",
      "6 4916466\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import oeis\n",
    "import functools\n",
    "import torch\n",
    "\n",
    "path = '/Users/nolte/Dropbox/ML'\n",
    "\n",
    "cache_path = \"./data\"\n",
    "os.makedirs(cache_path, exist_ok=True)\n",
    "\n",
    "def readESymb(loop, path, file):\n",
    "    name = os.path.join(path, file)\n",
    "    assert os.path.isfile(name), name\n",
    "    res = ''\n",
    "    prefix = 'Esymb'\n",
    "    with open(name, 'rt') as f:\n",
    "        reading_form = False\n",
    "        for line in f:\n",
    "            if not reading_form:\n",
    "                if not line.startswith(prefix + '[' + str(loop) + ']'): continue\n",
    "                res = ''\n",
    "                reading_form = True\n",
    "            res += line[:-2] if line[-2] == '\\\\' else line[:-1]\n",
    "            if line[-2] in [\":\", \";\"]:\n",
    "                break\n",
    "    return res\n",
    "\n",
    "\n",
    "def convert(loop):\n",
    "    file = 'EZ6_symb_new_norm' if loop == 6 else 'EZ_symb_new_norm'\n",
    "    s = re.split(\":=|SB\\(|\\)\", re.sub('[,*]', '', readESymb(loop, path, file)))[1:-1]\n",
    "    keys = s[1::2]\n",
    "    values = [int(re.sub('[+-]$',t[0]+'1',t)) for t in s[0::2]]\n",
    "    return {k:v for k,v in zip(keys,values)}\n",
    "\n",
    "\n",
    "\n",
    "def query_key(key,verbose=False):\n",
    "    l = len(key)\n",
    "    if l==0:\n",
    "        if verbose: print('empty key')\n",
    "        return 0\n",
    "    if l%2==1:\n",
    "        if verbose: print(\"odd length key\")\n",
    "        return 0\n",
    "    if key[0] in ['d', 'e', 'f'] or key[-1] in ['a', 'b', 'c']:\n",
    "        if verbose: print(\"stupid zero: begin/end\")\n",
    "        return 0\n",
    "    for i in range(l-1):\n",
    "        if (key[i] == 'a' and key[i+1] == 'd') \\\n",
    "            or (key[i] == 'b' and key[i+1] == 'e') \\\n",
    "            or (key[i] == 'c' and key[i+1] == 'f'):\n",
    "                if verbose: print('stupid zero: adjacency')\n",
    "                return 0\n",
    "        if (key[i] == 'd' and key[i+1] in ['a','e','f'])\\\n",
    "            or (key[i] == 'e' and key[i+1] in ['b','d','f'])\\\n",
    "            or (key[i] == 'f' and key[i+1] in ['c','d','e']):\n",
    "                if verbose: print('stupid zero: adjacency')\n",
    "                return 0\n",
    "\n",
    "\n",
    "    loop  = l//2\n",
    "    if loop < 1 or loop > 6:\n",
    "        print(\"loop:\", loop, \"1 to 6 only:\")\n",
    "        return 0\n",
    "    if key in data[loop].keys():\n",
    "        return data[loop][key]\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "data = [[]]\n",
    "print(\"loading...\")\n",
    "for i in range(1,7):\n",
    "    e=convert(i)\n",
    "    data.append(e)\n",
    "print(\"loaded\")\n",
    "\n",
    "for i in range(7):\n",
    "    print(i, len(data[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(word, max_length=12):\n",
    "  result = [ord(c) - ord('a') + 1 for c in word]\n",
    "  result += [0] * (max_length - len(result))\n",
    "  return torch.tensor(result).long()\n",
    "\n",
    "all_data = [\n",
    "  (tokenize(word), torch.tensor([val]))\n",
    "  for i in range(1, 7)\n",
    "  for word, val in data[i].items()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = torch.stack([x[0] for x in all_data]), torch.stack([x[1] for x in all_data])\n",
    "torch.save((X, Y), os.path.join(cache_path, \"data.pt\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
